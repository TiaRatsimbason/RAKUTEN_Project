services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_database:/var/lib/postgresql/data
    container_name: postgres-db
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 10s
      retries: 5

  mongo:
    image: mongo:6.0.13
    ports:
      - "27017:27017"
    environment:
      - MONGODB_URI=mongodb://mongodb:27017/
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=motdepasseadmin
    volumes:
      - mongo_database-dev:/data/db
    container_name: rakuten-mongo
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  compass:
    image: mongo-express:latest
    ports:
      - "8081:8081"
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=admin
      - ME_CONFIG_MONGODB_ADMINPASSWORD=motdepasseadmin
      - ME_CONFIG_MONGODB_SERVER=mongo
      - ME_CONFIG_MONGODB_AUTH_DATABASE=admin
    depends_on:
      mongo:
        condition: service_healthy
    container_name: mongodb-compass


  api:
    image: rakuten-api:latest
    build:
      context: ../
      dockerfile: docker/api.Dockerfile
    ports:
      - "8000:8000"
    environment:
      MONGODB_URI: mongodb://admin:motdepasseadmin@mongo:27017/
      MLFLOW_TRACKING_URI: http://mlflow-ui:5000
      MLFLOW_ARTIFACT_URI: /app/mlruns
      PYTHONUNBUFFERED: 1
      LOG_LEVEL: DEBUG
      TF_ENABLE_ONEDNN_OPTS: 0
      CUDA_VISIBLE_DEVICES: -1
      PYTHONHTTPSVERIFY: 0
    volumes:
      - mlflow-artifacts:/app/mlruns
    depends_on:
      mongo:
        condition: service_started
      mlflow-ui:
        condition: service_healthy
    container_name: rakuten-api
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/docs"]
      interval: 30s
      timeout: 10s
      retries: 5

  mlflow-ui:
    build:
      context: ../
      dockerfile: docker/mlflow-ui.Dockerfile
    ports:
      - "5000:5000"
    environment:
      MONGODB_URI: mongodb://admin:motdepasseadmin@mongo:27017/
      MLFLOW_TRACKING_URI: http://mlflow-ui:5000
      MLFLOW_ARTIFACT_URI: /app/mlruns
    volumes:
      - mlflow-artifacts:/app/mlruns
      - mlflow-db:/app
    container_name: mlflow-ui
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5000/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  airflow-init:
    build:
      context: ../
      dockerfile: docker/airflow.Dockerfile
    user: "0:0"
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      AIRFLOW_HOME: /opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: >
      bash -c "
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins &&
        chmod -R 777 /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins &&
        chown -R airflow:root /opt/airflow &&
        airflow db init &&
        airflow users create -e admin@example.com -f Admin -l User -p admin -r Admin -u admin
      "
    depends_on:
      postgres:
        condition: service_healthy
    container_name: airflow-init

  airflow:
    build:
      context: ../
      dockerfile: docker/airflow.Dockerfile
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      AIRFLOW__CORE__LOGGING_CONFIG_CLASS: airflow.config_templates.airflow_local_settings.DEFAULT_LOGGING_CONFIG
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
    volumes:
      - type: bind
        source: ./dags
        target: /opt/airflow/dags
      - type: bind
        source: ./logs
        target: /opt/airflow/logs
      - type: bind
        source: ./plugins
        target: /opt/airflow/plugins
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
      - type: bind
        source: .
        target: /docker
      - type: bind
        source: ./.env.dev
        target: /docker/.env.dev
    command: webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    container_name: airflow
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow_scheduler:
    build:
      context: ../
      dockerfile: docker/airflow.Dockerfile
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      AIRFLOW__CORE__LOGGING_CONFIG_CLASS: airflow.config_templates.airflow_local_settings.DEFAULT_LOGGING_CONFIG
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
    volumes:
      - type: bind
        source: ./dags
        target: /opt/airflow/dags
      - type: bind
        source: ./logs
        target: /opt/airflow/logs
      - type: bind
        source: ./plugins
        target: /opt/airflow/plugins
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
      - type: bind
        source: .
        target: /docker
      - type: bind
        source: ./.env.dev
        target: /docker/.env.dev
    command: scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    container_name: airflow_scheduler

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  
      - GF_SECURITY_ADMIN_USER=admin     
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 5s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
        
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    restart: unless-stopped


volumes:
  mongo_database-dev:
  mlflow-artifacts: # Volume séparé pour les artéfacts MLflow
  mlflow-db:  # Nouveau volume pour MLflow
  postgres_database:
  grafana-storage:
  grafana-logs:
    driver: local
  airflow_logs:
